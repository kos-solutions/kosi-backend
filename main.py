from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from openai import OpenAI
import base64
import uvicorn
import os

app = FastAPI()

# IMPORTANT: cheia trebuie pusÄƒ Ã®n Railway â†’ Variables
client = OpenAI(api_key="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")


# ------------------ REQUEST MODELS ------------------

class StoryRequest(BaseModel):
    prompt: str

class TTSRequest(BaseModel):
    text: str


# ------------------ KOSI PROMPT ------------------

KOSI_SYSTEM_PROMPT = (
    "Tu eÈ™ti Kosi, un prieten AI cald, blÃ¢nd È™i empatic, creat special pentru copii. "
    "Vorbesti cu o voce jucÄƒuÈ™Äƒ È™i liniÈ™titoare. "
    "FoloseÈ™ti propoziÈ›ii scurte È™i simple. "
    "Nu foloseÈ™ti ton robotic sau cuvinte complicate. "
    "Nu moralizezi, nu dai ordine È™i nu sperii copilul. "
    "Oferi siguranÈ›Äƒ, Ã®ncurajare È™i cÄƒldurÄƒ. "
    "RÄƒspunsurile tale trebuie sÄƒ sune afectuos È™i pline de prietenie. "
)


# ------------------ STORY ENDPOINT ------------------

@app.post("/story")
async def story(request: StoryRequest):

    if not request.prompt.strip():
        raise HTTPException(status_code=400, detail="Prompt invalid")

    try:
        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": KOSI_SYSTEM_PROMPT},
                {"role": "user", "content": request.prompt}
            ],
            temperature=0.75,
            max_tokens=500
        )

        story_text = completion.choices[0].message["content"]
        return {"story": story_text}
@app.post("/story")
async def story(request: StoryRequest):

    if not request.prompt or request.prompt.strip() == "":
        return {"story": "Nu am Ã®nÈ›eles ce ai spus. Vrei sÄƒ mai zici o datÄƒ? ðŸ˜Š"}

    try:
        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": KOSI_SYSTEM_PROMPT},
                {"role": "user", "content": request.prompt}
            ],
            temperature=0.8,
            max_tokens=500
        )

        story_text = completion.choices[0].message["content"]
        return {"story": story_text}

    except Exception as e:
        # ðŸ”¥ IMPORTANT: returneazÄƒ ÃŽNTOTDEAUNA story, chiar È™i la eroare
        return {"story": f"Kosi are o micÄƒ problemÄƒ acum, dar revine imediat. ({str(e)})"}



# ------------------ TTS ENDPOINT ------------------

@app.post("/tts")
async def tts(request: TTSRequest):
    if not request.text.strip():
        raise HTTPException(status_code=400, detail="Text invalid pentru TTS")

    try:
        # OpenAI TTS â€“ model: gpt-4o-mini-tts (rapid, cald)
        audio_resp = client.audio.speech.create(
            model="gpt-4o-mini-tts",
            voice="verse",
            input=request.text
        )

        # Convertire Ã®n Base64 pentru Android
        audio_base64 = base64.b64encode(audio_resp).decode("utf-8")

        return {"audio": audio_base64}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))



# ------------------ SERVER START ------------------

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
